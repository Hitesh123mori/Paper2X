{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from typing import List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# from langchain.document_loaders import PyMuPDFLoader\n",
    "from typing import List, Dict, Any, Optional\n",
    "import fitz\n",
    "from pydantic import BaseModel, Field\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_PROJECT\"] = f\"MineD 2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"\n",
    "# headers = {\n",
    "#     \"Authorization\": \"Bearer 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\",\n",
    "#     \"Content-Type\": \"application/json\",\n",
    "#    \"x-wait-for-model\": \"true\"\n",
    "# }\n",
    "# data = {\n",
    "#     \"inputs\": \"Hey, give some idea about creating a podcast from res paper summary \"\n",
    "# }\n",
    "# response = requests.post(API_URL, headers=headers, json=data)\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "# llm = HuggingFaceEndpoint(\n",
    "#     # repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "#     repo_id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#     task=\"text-generation\", \n",
    "#     do_sample=False,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base model to hold the metadata, and slide summeries that the llm will extract\n",
    "class ResPaperText(BaseModel):\n",
    "    # authors: str = Field(..., description=\"List of authors of the research paper\")\n",
    "    # title: str = Field(..., description=\"Title of the research paper\")\n",
    "    # submission_date: str = Field(..., description=\"Submission date of the research paper\")\n",
    "    # keywords: List[str] = Field(..., description=\"List of keywords associated with the research paper\")\n",
    "    # references: List[str] = Field(..., description=\"List of references cited in the research paper\")\n",
    "    # abstract: str = Field(..., description=\"Abstract of the research paper\")\n",
    "    conclusion: str = Field(..., description=\"Conclusion of the research paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pydantic Model for PPT slides\n",
    "class SlideContent(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the particular slide\")\n",
    "    bullet_points: Optional[List[str]] = Field(None, description=\"Content in bullet points form for the slide\")\n",
    "    notes: Optional[str] = Field(None, description=\"Additional notes for the slide\")\n",
    "    images: Optional[List[str]] = Field(None, description=\"List of relevant image paths for the slide\")\n",
    "\n",
    "class PPTPresentation(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the presentation\")\n",
    "    authors: List[str] = Field(..., description=\"List of authors of the presentation\")\n",
    "    institution: str = Field(..., description=\"Institution associated with the presentation\")\n",
    "    slides: List[SlideContent] = Field(..., description=\"List of slides, in the presentation,which are SlideContent schemas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResPaperExtractState(TypedDict):\n",
    "    pdf_path: Optional[str] = None  # Path to the PDF file\n",
    "    extracted_text: Optional[str] = None  # Full extracted text from the PDF\n",
    "    extracted_images: Optional[List[str]] = None  # Paths to extracted images\n",
    "    slides_content: Optional[List[Dict[str, str]]] = None  # Prepared content for PowerPoint slides\n",
    "    metadata: str\n",
    "    ppt_object: PPTPresentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fitz\n",
    "# doc = fitz.open(r\"C:\\Users\\milap\\OneDrive\\Desktop\\CLG\\3rd YR\\SEM VI\\mined_2025\\lib\\server\\Milap_Tathya_ICC_June_2025.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(state: ResPaperExtractState):\n",
    "    pdf_path = state[\"pdf_path\"]\n",
    "    doc = fitz.open(pdf_path)  # Load the PDF only once\n",
    "    \n",
    "    extracted_text = []\n",
    "    extracted_images = []\n",
    "    output_folder = \"extracted_images\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through each page\n",
    "    for page_number, page in enumerate(doc):\n",
    "        # Extract text\n",
    "        text = page.get_text(\"text\")\n",
    "        extracted_text.append(text)\n",
    "\n",
    "        # Extract images\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            img_filename = f\"{output_folder}/page_{page_number+1}_img_{img_index+1}.{image_ext}\"\n",
    "            \n",
    "            with open(img_filename, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "            \n",
    "            extracted_images.append(img_filename)\n",
    "\n",
    "    # Combine text from all pages\n",
    "    full_text = \"\\n\".join(extracted_text)\n",
    "\n",
    "    # Update state\n",
    "    return {\"extracted_text\": full_text, \"extracted_images\": extracted_images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condenser_instruction = \"\"\" \n",
    "# You are an AI assistant specialized in processing research papers. \n",
    "\n",
    "# Here is the text extracted from a research paper: {extracted_text}\n",
    "\n",
    "# When tasked with extracting information from the provided text, follow these guidelines, and structure the content accordingly:\n",
    "# 1. **Metadata Extraction:** Identify and extract:\n",
    "#    - Authors  \n",
    "#    - Title  \n",
    "#    - Submission Date  \n",
    "#    - Keywords  \n",
    "#    - References (return as a list) \n",
    "\n",
    "# 2. **Text Structuring:** Organize the content into:\n",
    "#    - Abstract  \n",
    "#    - Conclusion  \n",
    "#    - Body (as a list of sections or paragraphs)  \n",
    "\n",
    "# Ensure the extracted content is well-structured, concise, and retains essential details.\n",
    "\n",
    "# \"\"\"\n",
    "# parser = PydanticOutputParser(pydantic_object=ResPaperText)\n",
    "\n",
    "# condenser_template = ChatPromptTemplate(\n",
    "#    messages=[(\"system\", condenser_instruction),\n",
    "#    (\"human\", \"Extract the details from the given text\")],\n",
    "#    input_variables=[\"extracted_text\"],\n",
    "#    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "# )\n",
    "# # summarizer = \"\"\" \n",
    "# # Please provide a concise summary of the following research text, highlighting the main points, key findings, and conclusions. \n",
    "# # Focus on summarizing the purpose of the study, the methods used, and the significant results, while avoiding unnecessary details. The text is as follows: {extracted_text}\n",
    "# # \"\"\"\n",
    "# summarizer = \"\"\"\n",
    "# \"You are an expert at creating PowerPoint presentations. Generate a PowerPoint (PPT) presentation that summarizes a research paper. Follow these guidelines:\"\n",
    "\n",
    "# Title Slide:\n",
    "\n",
    "# Include the title of the research paper.\n",
    "# Mention the author(s) and the institution (if available).\n",
    "# Introduction Slide:\n",
    "\n",
    "# Summarize the research problem and objectives.\n",
    "# Highlight the motivation behind the study.\n",
    "# Methods Slide:\n",
    "\n",
    "# Briefly explain the research methodology.\n",
    "# Mention key techniques, datasets, or experimental setups used.\n",
    "# Results Slide:\n",
    "\n",
    "# Summarize the major findings of the study.\n",
    "# Use bullet points or simple visuals (graphs, tables) to illustrate key results.\n",
    "# Discussion/Analysis Slide:\n",
    "\n",
    "# Explain the significance of the results.\n",
    "# Compare findings with previous research (if applicable).\n",
    "# Conclusion Slide:\n",
    "\n",
    "# Summarize key takeaways from the research.\n",
    "# Mention potential future work or applications of the study.\n",
    "# References Slide:\n",
    "\n",
    "# Include citations or sources (if necessary).\n",
    "# Additional Instructions:\n",
    "\n",
    "# Keep the slides concise with minimal text (bullet points preferred).\n",
    "# Use visuals like diagrams, graphs, or charts where applicable.\n",
    "# Maintain a professional and visually appealing slide design.\n",
    "\n",
    "# Here is the given text: {extracted_text}\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# # Initialize the Output Parser\n",
    "# parser = PydanticOutputParser(pydantic_object=PPTPresentation)\n",
    "# summarizer_temp = PromptTemplate(\n",
    "#    template=summarizer,\n",
    "#    input_variables=[\"extracted_text\"],\n",
    "#    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "# )\n",
    "# def get_data(state: ResPaperExtractState):\n",
    "#    extracted_text = state[\"extracted_text\"]\n",
    "#    #  structured_llm = llm.with_structured_output(ResPaperText)\n",
    "#    #  condenser_prompt = condenser_template.format(extracted_text=extracted_text)\n",
    "#    #  response = structured_llm.invoke(condenser_prompt)\n",
    "#    response = llm.invoke(summarizer_temp.format(extracted_text=extracted_text))\n",
    "#    ppt_object = parser.invoke(response)\n",
    "\n",
    "#    return {\"ppt_object\": ppt_object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in creating PowerPoint presentations. Generate a structured PowerPoint (PPT) presentation \n",
    "    that summarizes a research paper based on the provided extracted text. Follow these instructions:\n",
    "    \n",
    "    Remember that the objective of this PPT is for a third party to understand the key points of the research paper, and \n",
    "    give them a gist of the research paper.\n",
    "\n",
    "    - Title Slide: Include the research paper title, authors, and institution.\n",
    "    - Introduction Slide: Summarize the problem, objectives, and motivation.\n",
    "    - Methods Slide: Briefly explain the methodology, datasets, and experimental setup.\n",
    "    - Results Slide: Summarize key findings with bullet points. Mention any visuals (graphs, tables) found from the extracted text. You should definetly mention in the presentation any figures related to a performance metric or tables that are mentioned in the extracted text.\n",
    "    - Discussion Slide: Explain the significance of results and compare with prior work.\n",
    "    - Conclusion Slide: Summarize key takeaways and potential future work.\n",
    "    - References Slide: Include citations if available.\n",
    "\n",
    "    Additional Guidelines:\n",
    "    - Keep slides concise (use bullet points).\n",
    "    - Maintain a professional and visually appealing slide design.\n",
    "    - Give the text in markdown format.\n",
    "    - Each slide should have rich information content, summarizing the information related to the particular slide heading, \n",
    "    and also include some content that is related to the slide heading but not directly mentioned in the extracted text.\n",
    "    - Also keep in mind that the text for each slide should not be too lengthy, and should be concise and to the point.\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Human Message: Supplies extracted text from the research paper\n",
    "human_message = HumanMessagePromptTemplate.from_template(\"Here is the extracted text:\\n\\n{extracted_text}\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=PPTPresentation)\n",
    "# Combine into a structured chat prompt\n",
    "chat_prompt = ChatPromptTemplate(\n",
    "    messages=[system_message, human_message],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "def get_data(state):\n",
    "    extracted_text = state[\"extracted_text\"]\n",
    "    \n",
    "    # Format prompt with extracted text\n",
    "    \n",
    "    # Invoke LLM with structured output\n",
    "    chain = chat_prompt | llm | parser\n",
    "\n",
    "    # Parse structured output into Pydantic model\n",
    "    ppt_object = chain.invoke({\"extracted_text\":extracted_text})\n",
    "    \n",
    "    return {\"ppt_object\": ppt_object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(ResPaperExtractState)\n",
    "\n",
    "builder.add_node(\"pdf-2-text\", load_pdf)\n",
    "builder.add_node(\"text-condensation\", get_data)\n",
    "\n",
    "builder.add_edge(START, \"pdf-2-text\")\n",
    "builder.add_edge(\"pdf-2-text\", \"text-condensation\")\n",
    "builder.add_edge(\"text-condensation\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = r\"C:\\Users\\milap\\OneDrive\\Desktop\\CLG\\3rd YR\\SEM VI\\mined_2025\\lib\\server\\Milap_Tathya_ICC_June_2025.pdf\"\n",
    "path2 = r\"C:\\Users\\milap\\OneDrive\\Desktop\\CLG\\3rd YR\\SEM VI\\mined_2025\\lib\\server\\STORM.pdf\"\n",
    "path3 = r\"C:\\Users\\milap\\OneDrive\\Desktop\\CLG\\3rd YR\\SEM VI\\mined_2025\\lib\\server\\SuFIA.pdf\"\n",
    "path4 = r\"C:\\Users\\milap\\OneDrive\\Desktop\\CLG\\3rd YR\\SEM VI\\mined_2025\\lib\\server\\ankit review.pdf\"\n",
    "state_output = graph.invoke({\"pdf_path\":path3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(state_output[\"ppt_object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Introduction', 'bullet_points': ['Problem: Current robotic surgical assistants (RSAs) often require tedious teleoperation, leading to surgeon fatigue and limiting autonomy.', 'Objectives: Develop SUFIA, a framework for natural language-guided augmented dexterity in RSAs.', 'Motivation:  Enable learning-free, generalizable surgical sub-task execution with a human-in-the-loop safety mechanism. Overcome limitations of learning-based approaches which are computationally expensive, require extensive data, and lack generalizability.', 'Improve human-robot interaction in surgery through natural language commands.'], 'notes': 'Highlight the gap in current technology and how SUFIA addresses it.  Emphasize the benefits of a language-guided approach.'}\n"
     ]
    }
   ],
   "source": [
    "ppt_content = state_output[\"ppt_object\"]\n",
    "# print(ppt_content)\n",
    "print(ppt_content[\"slides\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Masoud Moghani',\n",
       " 'Lars Doorenbos',\n",
       " 'William Chung-Ho Panitch',\n",
       " 'Sean Huver',\n",
       " 'Mahdi Azizian',\n",
       " 'Ken Goldberg',\n",
       " 'Animesh Garg']"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt_content[\"authors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PowerPoint presentation saved as sufia.pptx\n"
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Pt, Inches\n",
    "from pptx.enum.text import PP_ALIGN, MSO_ANCHOR, MSO_AUTO_SIZE\n",
    "\n",
    "def create_ppt_from_dict(ppt_data: dict, output_file: str = \"presentation.pptx\"):\n",
    "    prs = Presentation()\n",
    "    slide_width = prs.slide_width\n",
    "    slide_height = prs.slide_height\n",
    "\n",
    "    # Title Slide Fix\n",
    "    title_slide_layout = prs.slide_layouts[0]  # Title slide layout\n",
    "    title_slide = prs.slides.add_slide(title_slide_layout)\n",
    "    title = title_slide.shapes.title\n",
    "    main_title = title_slide.placeholders[0]\n",
    "    main_title.top = Inches(2.5)  # Adjust the value as needed\n",
    "    main_title.width = Inches(9)  # Set the width to a desired value\n",
    "    main_title.left = (slide_width - main_title.width) // 2\n",
    "    subtitle = title_slide.placeholders[1]\n",
    "    subtitle.top = Inches(5.5)  # Adjust the value as needed\n",
    "    subtitle.width = Inches(10)  # Set the width to a desired value\n",
    "\n",
    "    # Title Formatting\n",
    "    title.text = ppt_data.get(\"title\", \"Presentation Title\")\n",
    "    title.text_frame.paragraphs[0].font.size = Pt(40)  # Adjust title font size\n",
    "    title.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER  # Ensure center alignment\n",
    "\n",
    "    # Subtitle Formatting (Author & Institution)\n",
    "    subtitle.text = \", \".join(ppt_data.get(\"authors\", [])) + \"\\n\" + \", \".join(ppt_data.get(\"institution\", []))\n",
    "    subtitle.text_frame.paragraphs[0].font.size = Pt(18)  # Reduce subtitle font size\n",
    "    subtitle.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "\n",
    "    # Adjust Subtitle Positioning\n",
    "    left = subtitle.left\n",
    "    top = int(subtitle.top * 0.7)  # Move subtitle slightly up\n",
    "    width = subtitle.width\n",
    "    height = subtitle.height\n",
    "    subtitle.text_frame.auto_size = MSO_AUTO_SIZE.SHAPE_TO_FIT_TEXT\n",
    "    subtitle.text_frame.word_wrap = True\n",
    "\n",
    "    subtitle.text_frame.margin_top = Pt(15)  # Reduce top margin\n",
    "    subtitle.text_frame.margin_bottom = Pt(5)  # Reduce bottom margin\n",
    "    subtitle.text_frame.vertical_anchor = MSO_ANCHOR.MIDDLE  # Center text in box\n",
    "\n",
    "    # Add content slides\n",
    "    for i in range(1, len(ppt_data[\"slides\"])):\n",
    "        slide_data = ppt_data[\"slides\"][i]\n",
    "        # Use a different layout for content slides to avoid duplicating the title slide layout\n",
    "        slide_layout = prs.slide_layouts[1]  # Title & Content layout for content slides\n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        title = slide.shapes.title\n",
    "        content = slide.placeholders[1]\n",
    "\n",
    "        title.text = slide_data.get(\"title\", \"Slide Title\")\n",
    "        \n",
    "        bullet_points = slide_data.get(\"bullet_points\", [])\n",
    "        if bullet_points:\n",
    "            text_frame = content.text_frame\n",
    "            text_frame.clear()  # Remove default placeholder text\n",
    "            text_frame.word_wrap = True  # Enable text wrapping\n",
    "            text_frame.auto_size = MSO_AUTO_SIZE.SHAPE_TO_FIT_TEXT  # Enable auto size for content\n",
    "\n",
    "            # Set default font size based on slide type\n",
    "            is_references = \"references\" in slide_data.get(\"title\", \"\").lower()\n",
    "            DEFAULT_FONT_SIZE = 14 if is_references else 24\n",
    "\n",
    "            # Add bullet points\n",
    "            for point in bullet_points:\n",
    "                p = text_frame.add_paragraph()\n",
    "                p.text = point\n",
    "                p.font.size = Pt(DEFAULT_FONT_SIZE)\n",
    "\n",
    "            # Adjust font size dynamically for non-references slides\n",
    "        \n",
    "\n",
    "    # Save PowerPoint file\n",
    "    prs.save(output_file)\n",
    "    print(f\"PowerPoint presentation saved as {output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "create_ppt_from_dict(ppt_content, \"sufia.pptx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
