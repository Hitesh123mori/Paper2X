{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from typing import List, Dict, Any\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import os\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "from typing import List, Dict, Any, Optional\n",
    "import fitz # type: ignore\n",
    "from pydantic import BaseModel, Field # type: ignore\n",
    "import regex as re\n",
    "import string\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGSMITH_PROJECT\"] = f\"MineD 2025\"\n",
    "os.environ[\"GOOGLE_API_KEY\"] = f\"AIzaSyBQU_iCwA34u1XbnJcekcNEOkgFb3PHJZM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResPaperText(BaseModel):\n",
    "    authors: str = Field(..., description=\"List of authors of the research paper\")\n",
    "    title: str = Field(..., description=\"Title of the research paper\")\n",
    "    submission_date: str = Field(..., description=\"Submission date of the research paper\")\n",
    "    keywords: List[str] = Field(..., description=\"List of keywords associated with the research paper\")\n",
    "    references: List[str] = Field(..., description=\"List of references cited in the research paper\")\n",
    "    abstract: str = Field(..., description=\"Abstract of the research paper\")\n",
    "    conclusion: str = Field(..., description=\"Conclusion of the research paper\")\n",
    "    summary: str = Field(..., description=\"Summary of the research paper\")\n",
    "\n",
    "class SlideContent(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the particular slide\")\n",
    "    bullet_points: Optional[List[str]] = Field(None, description=\"Content in bullet points form for the slide\")\n",
    "    notes: Optional[str] = Field(None, description=\"Additional notes for the slide\")\n",
    "    images: Optional[List[str]] = Field(None, description=\"List of relevant image paths for the slide\")\n",
    "\n",
    "class PPTPresentation(BaseModel):\n",
    "    title: str = Field(..., description=\"Title of the presentation\")\n",
    "    authors: List[str] = Field(..., description=\"List of authors of the presentation\")\n",
    "    institution: str = Field(..., description=\"Institution associated with the presentation\")\n",
    "    slides: List[SlideContent] = Field(..., description=\"List of slides, in the presentation,which are SlideContent schemas.\")\n",
    "    \n",
    "\n",
    "class Dialogue(BaseModel):\n",
    "    text: str = Field(..., description=\"The text of dialogue\")\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    katherine: List[Dialogue] = Field(..., description=\"Katherine's dialogues\")\n",
    "    clay: List[Dialogue] = Field(..., description=\"Clay's dialogues\")\n",
    "    order: List[str] = Field(..., description=\"The order of dialogues denoted by the names of the speaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResPaperExtractState(TypedDict):\n",
    "    pdf_path: Optional[str] = None  # Path to the PDF file\n",
    "    extracted_text: Optional[str] = None  # Full extracted text from the PDF\n",
    "    extracted_images: Optional[List[str]] = None  # Paths to extracted images\n",
    "    slides_content: Optional[List[Dict[str, str]]] = None  # Prepared content for PowerPoint slides\n",
    "    metadata: str\n",
    "    ppt_object: PPTPresentation\n",
    "    convo: Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(state: ResPaperExtractState):\n",
    "    pdf_path = state[\"pdf_path\"]\n",
    "    doc = fitz.open(pdf_path)  # Load the PDF only once\n",
    "    \n",
    "    extracted_text = []\n",
    "    extracted_images = []\n",
    "    output_folder = \"extracted_images\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Iterate through each page\n",
    "    for page_number, page in enumerate(doc):\n",
    "        # Extract text\n",
    "        text = page.get_text(\"text\")\n",
    "        extracted_text.append(text)\n",
    "\n",
    "        # Extract images\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image_ext = base_image[\"ext\"]\n",
    "            img_filename = f\"{output_folder}/page_{page_number+1}_img_{img_index+1}.{image_ext}\"\n",
    "            \n",
    "            with open(img_filename, \"wb\") as img_file:\n",
    "                img_file.write(image_bytes)\n",
    "            \n",
    "            extracted_images.append(img_filename)\n",
    "\n",
    "    # Combine text from all pages\n",
    "    full_text = \"\\n\".join(extracted_text)\n",
    "\n",
    "    # Update state\n",
    "    return {\"extracted_text\": full_text, \"extracted_images\": extracted_images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_condensation = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are an expert AI based researcher, your task is to find out key innovations and the overall summary from a given research paper, you should include the brief information about the authors of the paper,\n",
    "    The type of paper, the domain of the research paper,title, author, submission date, summary, literature review, methods used, results, discussion, conclusion and references of the given paper.\n",
    "    \n",
    "    Try to quantify the summary wherever necessary, also include number of result sections in the conclusion\n",
    "    \n",
    "    The summary should contain the simplified summary of the research paper, not the actual abstract, make sure it is lengthy enough to cover all the ideas discussed in the paper, under 2000 words. \n",
    "    \n",
    "    Additional information: \n",
    "        - Dont leave out any ideas from the paper\n",
    "        - Use your knowledge to connects the dots for very hard concepts\n",
    "        - Give a summary in under 2000 words\n",
    "        - Also present any innovative ideas to carry out this work\n",
    "        - Give output in json format\n",
    "    \n",
    "    The format for the extraction is as follows: {format_instructions}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Human Message: Supplies extracted text from the research paper\n",
    "human_message_condensation = HumanMessagePromptTemplate.from_template(\"Here is the extracted text:\\n\\n{extracted_text}\")\n",
    "\n",
    "parser_metadata = JsonOutputParser(pydantic_object=ResPaperText)\n",
    "# Combine into a structured chat prompt\n",
    "chat_prompt_metadata = ChatPromptTemplate(\n",
    "    messages=[system_message_condensation, human_message_condensation],\n",
    "    partial_variables={\"format_instructions\": parser_metadata.get_format_instructions()}\n",
    ")\n",
    "\n",
    "def condense_data(state):\n",
    "    extracted_text = state[\"extracted_text\"]\n",
    "    \n",
    "    prompt = chat_prompt_metadata.invoke({\"extracted_text\":extracted_text})\n",
    "    llm_out = llm.invoke(prompt)\n",
    "    llm_out.content = llm_out.content.replace(\"```json\", \"```\")\n",
    "    parsed = parser_metadata.invoke(llm_out)\n",
    "    \n",
    "    return {\"metadata\": parsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_ppt = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in creating PowerPoint presentations. Generate a structured PowerPoint (PPT) presentation \n",
    "    that summarizes a research paper based on the provided extracted text. Follow these instructions:\n",
    "    \n",
    "    Remember that the objective of this PPT is for a third party to understand the key points of the research paper, and \n",
    "    give them a gist of the research paper.\n",
    "\n",
    "    - Title Slide: Include the research paper title, authors, and institution.\n",
    "    - Introduction Slide: Summarize the problem, objectives, and motivation.\n",
    "    - Methods Slide: Briefly explain the methodology, datasets, and experimental setup.\n",
    "    - Results Slide: Summarize key findings with bullet points. Mention any visuals (graphs, tables) found from the extracted text. You should definetly mention in the presentation any figures related to a performance metric or tables that are mentioned in the extracted text.\n",
    "    - Discussion Slide: Explain the significance of results and compare with prior work.\n",
    "    - Conclusion Slide: Summarize key takeaways and potential future work.\n",
    "    - References Slide: Include citations if available.\n",
    "\n",
    "    Additional Guidelines:\n",
    "    - Keep slides concise (use bullet points).\n",
    "    - Maintain a professional and visually appealing slide design.\n",
    "    - Give the text in markdown format.\n",
    "    - Each slide should have rich information content, summarizing the information related to the particular slide heading, \n",
    "    and also include some content that is related to the slide heading but not directly mentioned in the extracted text.\n",
    "    - Also keep in mind that the text for each slide should not be too lengthy, and should be concise and to the point.\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Human Message: Supplies extracted text from the research paper\n",
    "human_message_ppt = HumanMessagePromptTemplate.from_template(\"Here is the summary of the research paper:\\n\\n{metadata}\")\n",
    "parser_ppt = JsonOutputParser(pydantic_object=PPTPresentation)\n",
    "\n",
    "# Combine into a structured chat prompt\n",
    "chat_prompt_ppt = ChatPromptTemplate(\n",
    "    messages=[system_message_ppt, human_message_ppt],\n",
    "    partial_variables={\"format_instructions\": parser_ppt.get_format_instructions()}\n",
    ")\n",
    "\n",
    "def get_ppt_data(state):\n",
    "    metadata = state[\"metadata\"]\n",
    "    prompt = chat_prompt_ppt.invoke({\"metadata\": metadata, \"tone\": \"formal\"})\n",
    "    llm_out = llm.invoke(prompt)\n",
    "    parsed = parser_ppt.invoke(llm_out)\n",
    "    return {\"ppt_object\": parsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_podcast = SystemMessagePromptTemplate.from_template(\n",
    "    \"\"\"You are an expert in creating/writing scripts for podcast, consider the given scenario, Two people one girl and one boy who are completing their B.Tech degree this year are discussing the given research paper to create an podcast of this research paper\n",
    "    \n",
    "    Boy's Name: Clay\n",
    "    Girl's Name: Katherine\n",
    "    \n",
    "    The Girl has complete knowledge about this paper, while the boy doesn't know anything about the paper.\n",
    "    \n",
    "    Write a script for a podcast, wherein firstly the girl introduces the paper, but the boy seems clueless, so the boy ask the girl many questions about the paper.\n",
    "    \n",
    "    The boy's question should cover all the possible doubt that one can have regarding the paper, and the girl should answer that questions correctly.\n",
    "\n",
    "    General Guideline:\n",
    "    - Intro must include the name, application and the authors (and their institution)\n",
    "    - Consider the audience to be technically sound, so you can ue jargons\n",
    "    - The boys questions should cover all the aspects from methodology, results, literature review, etc\n",
    "    - Dont make it too obvious that they are discussing about the paper\n",
    "    - Make the order such that the question asked by clay in previous dialogue is answered by katherine in this dialogue.\n",
    "\n",
    "    Additional Guidelines:\n",
    "    - Output in JSON format, this JSON should have two keys, names of boys and girls, in lower case.\n",
    "    - Each key corresponds to a list, their dialogues in sequential manner\n",
    "    - Consider that the girl always starts first\n",
    "    - Also give the order of dialogues, that are to be taken in a sequence\n",
    "    - Make sure that the number of dialogues in the order and in the lists add up.\n",
    "    - Both of them dont have to speak alternatively, they can heave continuous dialogues\n",
    "    - Each and every question asked by clay has to be answered by katherine\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Human Message: Supplies extracted text from the research paper\n",
    "human_message_podcast = HumanMessagePromptTemplate.from_template(\"Here is the summary of research paper:\\n\\n{metadata}. \\nMake sure the tone is {tone}\")\n",
    "\n",
    "parser_podcast = JsonOutputParser(pydantic_object=Conversation)\n",
    "# Combine into a structured chat prompt\n",
    "chat_prompt_podcast = ChatPromptTemplate(\n",
    "    messages=[system_message_podcast, human_message_podcast],\n",
    "    partial_variables={\"format_instructions\": parser_podcast.get_format_instructions()}\n",
    ")\n",
    "\n",
    "def get_data_podcast(state):\n",
    "    metadata = state[\"metadata\"]\n",
    "    prompt = chat_prompt_podcast.invoke({\"metadata\": metadata, \"tone\": \"formal\"})\n",
    "    llm_out = llm.invoke(prompt)\n",
    "    # llm_out.content = llm_out.content.replace(\"```json\", \"```\")\n",
    "    parsed = parser_podcast.invoke(llm_out)\n",
    "    \n",
    "    return {\"convo\": parsed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(ResPaperExtractState)\n",
    "\n",
    "builder.add_node(\"pdf-2-text\", load_pdf)\n",
    "builder.add_node(\"text-condensation\", condense_data)\n",
    "# builder.add_node(\"make-ppt-text\", get_ppt_data)\n",
    "builder.add_node(\"make-podcast-text\", get_data_podcast)\n",
    "\n",
    "builder.add_edge(START, \"pdf-2-text\")\n",
    "builder.add_edge(\"pdf-2-text\", \"text-condensation\")\n",
    "# builder.add_edge(\"text-condensation\", \"make-ppt-text\")\n",
    "builder.add_edge(\"text-condensation\", \"make-podcast-text\")\n",
    "builder.add_edge(\"make-podcast-text\", END)\n",
    "# builder.add_edge( \"make-ppt-text\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\\\Users\\\\Mihir Patel\\\\Downloads\\\\1706.03762v7.pdf\"\n",
    "state_output = graph.invoke({\"pdf_path\": path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper introduces the Transformer, a novel neural network architecture based solely on attention mechanisms, eliminating recurrence and convolutions.  Evaluated on machine translation tasks, the Transformer surpasses existing models in quality, parallelization, and training speed.  It achieves a 28.4 BLEU score on the WMT 2014 English-to-German task and a 41.8 BLEU score on the WMT 2014 English-to-French task, setting new state-of-the-art results.  The model's generalizability is demonstrated through successful application to English constituency parsing.\n",
      "This research paper, authored by a team of researchers primarily from Google Brain and Google Research, introduces the Transformer, a groundbreaking neural network architecture for sequence transduction tasks.  The key innovation lies in its reliance solely on attention mechanisms, abandoning the traditional recurrent and convolutional layers used in previous state-of-the-art models like recurrent neural networks (RNNs) and convolutional sequence-to-sequence models (ConvS2S). This departure allows for significantly greater parallelization during training, leading to substantial reductions in training time.  The authors detail the architecture of the Transformer, which consists of an encoder and a decoder, both composed of stacked layers incorporating multi-head self-attention and position-wise feed-forward networks.  The multi-head self-attention mechanism is a crucial component, enabling the model to attend to different parts of the input sequence simultaneously and capture long-range dependencies more effectively than previous methods.  The scaled dot-product attention mechanism is introduced to address the vanishing gradient problem associated with large dot products in the attention calculation.  The paper also discusses positional encoding, a technique used to incorporate information about the order of words in the input sequence, which is crucial since the Transformer lacks recurrence or convolution.  The researchers conducted extensive experiments on two widely used machine translation datasets (WMT 2014 English-to-German and English-to-French).  Their results demonstrate that the Transformer significantly outperforms existing models, achieving a new state-of-the-art BLEU score of 28.4 on the English-to-German task and 41.8 on the English-to-French task, with substantially lower training costs.  Furthermore, they showcase the Transformer's versatility by applying it to English constituency parsing, achieving competitive results even with limited training data.  The paper concludes by highlighting the potential of attention-based models and outlining future research directions, including extending the Transformer to other modalities and exploring more efficient attention mechanisms for handling very long sequences.  The innovative ideas in this paper include the complete reliance on attention mechanisms, the introduction of multi-head self-attention, and the use of scaled dot-product attention to improve efficiency and gradient stability.  The use of sinusoidal positional encoding is also noteworthy, allowing the model to potentially extrapolate to longer sequences than seen during training. The paper provides a detailed analysis of the model's components and their impact on performance, demonstrating the effectiveness of the proposed architecture.\n"
     ]
    }
   ],
   "source": [
    "print(state_output[\"metadata\"]['abstract'])\n",
    "print(state_output[\"metadata\"]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n",
      "['katherine', 'clay', 'katherine', 'clay', 'katherine', 'clay', 'katherine', 'clay', 'katherine', 'clay', 'katherine', 'clay', 'katherine']\n",
      "katherine: Hey Clay, ready to dive into this week's podcast topic?  It's a pretty groundbreaking paper, 'Attention is All You Need,' by Vaswani et al. from Google Brain and Google Research. It introduces the Transformer, a neural network architecture for sequence transduction tasks, focusing entirely on attention mechanisms.\n",
      "clay: Okay, I get the encoder-decoder structure, but this multi-head self-attention... can you explain that in more detail? How does it work, and why is it so crucial?\n",
      "katherine: The core idea is to replace recurrence and convolutions entirely with attention. This allows for significantly greater parallelization during training, leading to massive speedups.  They achieved state-of-the-art results on machine translation benchmarks like WMT 2014 English-to-German and English-to-French, and even showed promising results on English constituency parsing.\n",
      "clay: You mentioned scaled dot-product attention.  What's the 'scaling' part, and how does it address the vanishing gradient problem?  I'm not entirely clear on that.\n",
      "katherine: The architecture itself is composed of an encoder and a decoder, both built from stacked layers of multi-head self-attention and position-wise feed-forward networks.  The scaled dot-product attention is key; it helps manage the vanishing gradient problem often seen with large dot products in attention calculations.\n",
      "clay: How does the positional encoding work exactly?  Why is it necessary, and why did they choose sinusoidal functions?\n",
      "katherine: Positional encoding is crucial because, without recurrence or convolutions, the model needs a way to understand word order. They use sinusoidal functions for this, allowing potential extrapolation to longer sequences than seen during training.\n",
      "clay: The BLEU scores are impressive, but how do these compare to other state-of-the-art models at the time?  What were the specific models they were comparing against?\n",
      "katherine: Their results were quite impressive.  They achieved a BLEU score of 28.4 on the English-to-German task and 41.8 on the English-to-French task, significantly outperforming previous models.  The speed improvements were also substantial, thanks to the parallelization afforded by the attention-only architecture.\n",
      "clay: You mentioned a thorough analysis.  Did they perform any ablation studies to understand the contribution of each component (like multi-head attention or positional encoding) to the overall performance?\n",
      "katherine: The paper also delves into the details of the multi-head self-attention mechanism, which allows the model to attend to different parts of the input sequence simultaneously, capturing long-range dependencies more effectively.  They provide a thorough analysis of each component and its contribution to the overall performance.\n",
      "clay: What are some of the limitations of the Transformer architecture as discussed in the paper?  What are the potential challenges in applying it to other tasks or longer sequences?\n",
      "katherine: Finally, they discuss future research directions, such as extending the Transformer to other modalities and exploring more efficient attention mechanisms for handling extremely long sequences.  It's a really comprehensive and influential paper.\n"
     ]
    }
   ],
   "source": [
    "convo = state_output[\"convo\"]\n",
    "print(convo['katherine'].__len__())\n",
    "print(convo['clay'].__len__())\n",
    "print(convo['order'])\n",
    "\n",
    "kat_index = 0\n",
    "clay_index = 0\n",
    "\n",
    "for speaker in convo['order']:\n",
    "    dialogue = None\n",
    "    if speaker == 'katherine':\n",
    "        dialogue = convo['katherine'][kat_index]\n",
    "        kat_index += 1\n",
    "    else:\n",
    "        dialogue = convo['clay'][kat_index]\n",
    "        clay_index += 1\n",
    "    print(f\"{speaker}: {dialogue['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppt_content[\"authors\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Pt, Inches\n",
    "from pptx.enum.text import PP_ALIGN, MSO_ANCHOR, MSO_AUTO_SIZE\n",
    "\n",
    "def create_ppt_from_dict(ppt_data: dict, output_file: str = \"presentation.pptx\"):\n",
    "    prs = Presentation()\n",
    "    slide_width = prs.slide_width\n",
    "    slide_height = prs.slide_height\n",
    "\n",
    "    # Title Slide Fix\n",
    "    title_slide_layout = prs.slide_layouts[0]  # Title slide layout\n",
    "    title_slide = prs.slides.add_slide(title_slide_layout)\n",
    "    title = title_slide.shapes.title\n",
    "    main_title = title_slide.placeholders[0]\n",
    "    main_title.top = Inches(2.5)  # Adjust the value as needed\n",
    "    main_title.width = Inches(9)  # Set the width to a desired value\n",
    "    main_title.left = (slide_width - main_title.width) // 2\n",
    "    subtitle = title_slide.placeholders[1]\n",
    "    subtitle.top = Inches(5.5)  # Adjust the value as needed\n",
    "    subtitle.width = Inches(10)  # Set the width to a desired value\n",
    "\n",
    "    # Title Formatting\n",
    "    title.text = ppt_data.get(\"title\", \"Presentation Title\")\n",
    "    title.text_frame.paragraphs[0].font.size = Pt(40)  # Adjust title font size\n",
    "    title.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER  # Ensure center alignment\n",
    "\n",
    "    # Subtitle Formatting (Author & Institution)\n",
    "    subtitle.text = \", \".join(ppt_data.get(\"authors\", [])) + \"\\n\" + \", \".join(ppt_data.get(\"institution\", []))\n",
    "    subtitle.text_frame.paragraphs[0].font.size = Pt(18)  # Reduce subtitle font size\n",
    "    subtitle.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "\n",
    "    # Adjust Subtitle Positioning\n",
    "    left = subtitle.left\n",
    "    top = int(subtitle.top * 0.7)  # Move subtitle slightly up\n",
    "    width = subtitle.width\n",
    "    height = subtitle.height\n",
    "    subtitle.text_frame.auto_size = MSO_AUTO_SIZE.SHAPE_TO_FIT_TEXT\n",
    "    subtitle.text_frame.word_wrap = True\n",
    "\n",
    "    subtitle.text_frame.margin_top = Pt(15)  # Reduce top margin\n",
    "    subtitle.text_frame.margin_bottom = Pt(5)  # Reduce bottom margin\n",
    "    subtitle.text_frame.vertical_anchor = MSO_ANCHOR.MIDDLE  # Center text in box\n",
    "\n",
    "    # Add content slides\n",
    "    for i in range(1, len(ppt_data[\"slides\"])):\n",
    "        slide_data = ppt_data[\"slides\"][i]\n",
    "        # Use a different layout for content slides to avoid duplicating the title slide layout\n",
    "        slide_layout = prs.slide_layouts[1]  # Title & Content layout for content slides\n",
    "        slide = prs.slides.add_slide(slide_layout)\n",
    "        title = slide.shapes.title\n",
    "        content = slide.placeholders[1]\n",
    "\n",
    "        title.text = slide_data.get(\"title\", \"Slide Title\")\n",
    "        \n",
    "        bullet_points = slide_data.get(\"bullet_points\", [])\n",
    "        if bullet_points:\n",
    "            text_frame = content.text_frame\n",
    "            text_frame.clear()  # Remove default placeholder text\n",
    "            text_frame.word_wrap = True  # Enable text wrapping\n",
    "            text_frame.auto_size = MSO_AUTO_SIZE.SHAPE_TO_FIT_TEXT  # Enable auto size for content\n",
    "\n",
    "            # Set default font size based on slide type\n",
    "            is_references = \"references\" in slide_data.get(\"title\", \"\").lower()\n",
    "            DEFAULT_FONT_SIZE = 14 if is_references else 24\n",
    "\n",
    "            # Add bullet points\n",
    "            for point in bullet_points:\n",
    "                p = text_frame.add_paragraph()\n",
    "                p.text = point\n",
    "                p.font.size = Pt(DEFAULT_FONT_SIZE)\n",
    "\n",
    "            # Adjust font size dynamically for non-references slides\n",
    "        \n",
    "\n",
    "    # Save PowerPoint file\n",
    "    prs.save(output_file)\n",
    "    print(f\"PowerPoint presentation saved as {output_file}\")\n",
    "\n",
    "\n",
    "\n",
    "create_ppt_from_dict(ppt_content, \"sufia.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mined_2025-9loJUqGE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
